# Digitizing Piping and Instrumentation Diagrams: A YOLOv5-Based Approach with Tile-Segmentation and Majority Voting 

This repository contains code and resources for detecting and classifying components in Piping and Instrumentation Diagrams (P&IDs) using the YOLOv5 deep learning model. The project explores three different inference approachesâ€”full image processing, tile-based processing without majority voting, and tile-based processing with majority voting. Evaluation metrics including accuracy, precision, recall, F1-Score, average IoU, and inference time are reported to assess the effectiveness of each approach. 

## Table of Contents

- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Model Training](#model-training)
- [Inference Scenarios](#inference-scenarios)
- [Results](#results)



## Project Overview

This project aims to automate the analysis of P&IDs, which are widely used in industries to document equipment, piping, and control systems. The YOLOv5 model is used to detect and classify P&ID components, such as valves, pumps, and sensors. We compare three inference scenarios:

1. **Full Image Processing**: YOLOv5 processes the entire image in a single pass.
2. **Tile-Based Processing without Majority Voting**: The image is split into overlapping tiles, each processed independently.
3. **Tile-Based Processing with Majority Voting**: The image is split into overlapping tiles, and results are merged with a majority voting mechanism to improve accuracy.

## Dataset

The trained YOLOv5 model's dataset is obtained from here: https://www.kaggle.com/datasets/hristohristov21/pid-symbols 

**Note**: In the dataset, please delete `train (2).txt` and `val (1).txt` as they containing duplicate data. Replace them with `train.txt` and `val.txt` instead which are available in this repository. These 2 files are created using `createTrainVal.py`.

The 3 inference scenarios are tested using this dataset:
https://drive.google.com/drive/u/1/folders/1gMm_YKBZtXB3qUKUpI-LF1HE_MgzwfeR

**Note**: This folder is downloaded and saved as `drive-download-20241024T173735Z-001.zip` which can be found in the `yolov5_p&ids`file.

## Model Training

The YOLOv5 model is fine-tuned on this dataset using an NVIDIA A100 GPU. The key training parameters are as follows:
- **Image Size**: 672x672
- **Batch Size**: 8
- **Epochs**: 20
- **Pretrained Weights**: `yolov5l.pt`

For detailed training configurations, see the `yolov5_p&ids` file.

Trained model's checkpoints can be found from here which including `best.pt`:
https://drive.google.com/drive/folders/1_1GDL2BZQPU4ETPDUm2sGwvAS-QKza9-?usp=sharing

## Inference Scenarios

### 1. Original Image Processing
In this baseline scenario, the entire P&ID image is fed to YOLOv5 in one pass. While computationally efficient, this approach may not capture densely packed symbols as accurately as the tile-based methods.

### 2. Tile-Based Processing without Majority Voting
Each image is split into overlapping 1280x1280 tiles, processed individually. This approach improves the detection of small and overlapping symbols but may produce duplicate bounding boxes without majority voting.

### 3. Tile-Based Processing with Majority Voting
Similar to the previous scenario, but a majority voting mechanism is applied to merge overlapping bounding boxes across tiles. This improves detection accuracy by reducing duplication and improving localization.


## Results

<div align="center">
    <img src="https://github.com/HengYpinn/Digitizing-PID-YOLOv5-with-Tile-Segmentation-Majority-Voting/blob/main/trained%20model.png" alt="Result of the trained model" width="20%">
    <p><strong>Result of the trained model</strong></p>
</div>
<br>
<div align="center">
    <img src="https://github.com/HengYpinn/Digitizing-PID-YOLOv5-with-Tile-Segmentation-Majority-Voting/blob/main/test%20result.png" alt="Evaluation metrics of each scenario" width="50%">
    <p><strong>Evaluation metrics of each scenario</strong></p>
</div>


